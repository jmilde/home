<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>ysmiraak.tensor documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="css/highlight.css" /><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Ysmiraak</span> <span class="project-version">2019.07.15</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><a href="ysmiraak.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>ysmiraak</span></div></a></li><li class="depth-2 branch"><a href="ysmiraak.core.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>core</span></div></a></li><li class="depth-2 branch"><a href="ysmiraak.native.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>native</span></div></a></li><li class="depth-2 branch"><a href="ysmiraak.repl.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>repl</span></div></a></li><li class="depth-2 branch"><a href="ysmiraak.specter.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>specter</span></div></a></li><li class="depth-2 current"><a href="ysmiraak.tensor.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>tensor</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="ysmiraak.tensor.html#var-dims"><div class="inner"><span>dims</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-flix"><div class="inner"><span>flix</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-inat"><div class="inner"><span>inat</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-jnat"><div class="inner"><span>jnat</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-mapx"><div class="inner"><span>mapx</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-mulx"><div class="inner"><span>mulx</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-plux"><div class="inner"><span>plux</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-rank"><div class="inner"><span>rank</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-size"><div class="inner"><span>size</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-subx"><div class="inner"><span>subx</span></div></a></li><li class="depth-1"><a href="ysmiraak.tensor.html#var-trax"><div class="inner"><span>trax</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">ysmiraak.tensor</h1><div class="doc"><div class="markdown"><p>playing with your tensors may cause blindness.</p></div></div><div class="public anchor" id="var-dims"><h3>dims</h3><div class="usage"><code>(dims x)</code><code>(dims ds x)</code></div><div class="doc"><div class="markdown"><p>returns the shape <code>(: Vect r Nat)</code> of tensor <em>x</em>, or reshapes it to new shape <em>ds</em>, if its size can be preserved.</p>
<p>unlike common reshaping rules which conveniently allow one -1 in the shape to specify an unknown dimension to be dynamically filled, the new shape here may contain any number of negative integers. any unassigned size is distributed among the negative axis according to their relative magnitude.</p>
<p>for example with <code>(dims ? (vec (range 6)))</code> the shape <code>[-2 3 -1]</code> produces a tensor of shape <code>[2 3 1]</code>, wheras <code>[-1 3 -1]</code> gets an exception message.</p>
<p>the purpose of this design is to simplify the logic of the implementation and to avoid special handling for edge cases, for example what happens when -1 meets a tensor of size zero, and what happens when multiple -1s are given but the remaining positive dimensions fill the size perfectly.</p>
<p>for other common ndarray manipulations, see <a href="ysmiraak.tensor.html#var-rank">rank</a> for flattening, <a href="ysmiraak.tensor.html#var-size">size</a> for broadcasting, <a href="ysmiraak.tensor.html#var-flix">flix</a> for transposition, and <a href="ysmiraak.tensor.html#var-subx">subx</a> for slicing and indexing.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L82">view source</a></div></div><div class="public anchor" id="var-flix"><h3>flix</h3><div class="usage"><code>(flix x)</code><code>(flix perm x)</code><code>(flix x a b &amp; abs)</code></div><div class="doc"><div class="markdown"><p>for transposition. the first case swaps the 2 outer-most axes. the second case performs the specified permutation. the third case takes an even number of axes and consecutively swaps each two.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L156">view source</a></div></div><div class="public anchor" id="var-inat"><h3>inat</h3><div class="usage"><code>(inat d i)</code></div><div class="doc"><div class="markdown"><p>ensures that integer <em>i</em> is positive. used for implementing negative indexing. works under the condition that <code>-d-1 &lt; i &lt; d</code>. see <a href="ysmiraak.tensor.html#var-jnat">jnat</a> for an inclusive variant.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L49">view source</a></div></div><div class="public anchor" id="var-jnat"><h3>jnat</h3><div class="usage"><code>(jnat d i)</code></div><div class="doc"><div class="markdown"><p>like <a href="ysmiraak.tensor.html#var-inat">inat</a> but inclusive, namely <code>-d-1 &lt;= i &lt;= d</code>. used for implementing negative slicing.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L58">view source</a></div></div><div class="public anchor" id="var-mapx"><h3>mapx</h3><div class="usage"><code>(mapx r f)</code><code>(mapx r f x)</code><code>(mapx r f x &amp; xs)</code></div><div class="doc"><div class="markdown"><p>like <a href="https://clojuredocs.org/clojure.core/mapv">mapv</a> but for tensors, aka higher rank vectors in this implementation. anything that’s not a <a href="https://clojuredocs.org/clojure.core/vector_q">vector?</a> is treated as a rank-0 tensor, aka a scalar of sorts.</p>
<p>the first argument <em>r</em> is a non-negative integer, which is the rank of the tensors where the function <em>f</em> applies.</p>
<pre><code class="clojure">(mapx 2 inc [[0 1] [2 3]])               =&gt; [[1 2] [3 4]]
(mapx 2  +  [[0 1] [2 3]] [[1 2] [3 4]]) =&gt; [[1 3] [5 7]]
</code></pre>
<p>it does not have to be applied to the lowest level where the scalars live. for a rank-r tensor, any integer between <em>0</em> and <em>r</em> inclusive is applicable.</p>
<pre><code class="clojure">(mapx 1 peek [[0 1] [2 3]]) =&gt; [1 3]
(mapx 0 str  [[0 1] [2 3]]) =&gt; "[[0 1] [2 3]]"
</code></pre>
<p>it may be more intuitive to think of <em>r</em> as the axis instead of the rank. except that a rank-0 tensor has no axis but <code>r = 0</code> is still valid, and, like indices, axes are not inclusive on both ends.</p>
<p>note that the arity-2 case does not produce a transducer, since it operates on vectors and not lazy sequences. instead it produces a partial function. in general <code>(mapx 0 f)</code> is equivalent to <code>f</code> and <code>(partial mapx 1)</code> equivalent to <code>mapv</code>.</p>
<p>see <a href="ysmiraak.tensor.html#var-plux">plux</a> for a similar function which supports negative indexing and broadcasting semantics. also see <a href="ysmiraak.tensor.html#var-mulx">mulx</a> and <a href="ysmiraak.tensor.html#var-trax">trax</a> for tensor algebra operations.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L3">view source</a></div></div><div class="public anchor" id="var-mulx"><h3>mulx</h3><div class="usage"><code>(mulx r f x &amp; xs)</code></div><div class="doc"><div class="markdown"><p>tensor product.</p>
<ul>
  <li>
  <p>if <em>r</em> is negative, only axes up to rank <em>r</em> are tensored over. the dimensions of axes above <em>r</em> for all input tensors have to be compatible for broadcasting.</p></li>
  <li>
  <p>otherwise it’s the opposite. only axes above rank <em>r</em> are tensored over. as a result <code>r = 0</code> and <code>r = -1</code> are equivalent.</p></li>
</ul>
<p>in both cases <em>f</em> is applied across the final tensored axis, which when <code>-1 &lt;= r</code> is always the final axis.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L251">view source</a></div></div><div class="public anchor" id="var-plux"><h3>plux</h3><div class="usage"><code>(plux r f x)</code><code>(plux r f x &amp; xs)</code></div><div class="doc"><div class="markdown"><p>like <a href="ysmiraak.tensor.html#var-mapx">mapx</a> but supports broadcasting and negative indexing.</p>
<p>this function can be used to broadcast tensors together.</p>
<pre><code class="clojure">(as-&gt; (plux 0 vector x y z) [x y z] ... )
</code></pre></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L234">view source</a></div></div><div class="public anchor" id="var-rank"><h3>rank</h3><div class="usage"><code>(rank x)</code><code>(rank r x)</code></div><div class="doc"><div class="markdown"><p>returns the rank <code>(: Nat)</code> of tensor <em>x</em>, or changes its rank to <em>r</em> by flattening or wrapping the outer-most axes.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L66">view source</a></div></div><div class="public anchor" id="var-size"><h3>size</h3><div class="usage"><code>(size x)</code><code>(size ds x)</code></div><div class="doc"><div class="markdown"><p>returns the size <code>(: Nat)</code> of tensor <em>x</em>, or changes its size by broadcasting to shape <em>ds</em>, if the broadcasting logic is satisfied.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L137">view source</a></div></div><div class="public anchor" id="var-subx"><h3>subx</h3><div class="usage"><code>(subx x)</code><code>(subx x &amp; subs)</code></div><div class="doc"><div class="markdown"><p>for subscripting. each <em>sub</em> can be one of the following.</p>
<ul>
  <li>
  <p>an integer, for indexing. this collapses the axis it’s applied to thus reduces the tensor rank.</p></li>
  <li>
  <p>a map with <code>:i :j :k</code> keys, for (strided) slicing. the three values are integers, and work analogously to the arguments of <a href="https://clojuredocs.org/clojure.core/range">range</a>, also in the default cases with missing keys. the default values allows an empty map to slice the whole axis.</p></li>
  <li>
  <p>a sequence of booleans, for masking. the sequence needs not be a vector, but must have the same length as the dimension of that axis.</p></li>
  <li>
  <p>a sequence of integers, which returns the entries along that axis in the specified order, allowing duplicates. an empty sequence returns an empty axis. this is the most generic case. any input not of the previous cases is interpreted this way. for example <code>nil</code> is treated as an empty sequence.</p></li>
</ul>
<p>negative indices are supported in all cases where integers are used. but index-out-of-bound errors are not tolerated. the <em>subs</em> are applied consequetively from the outer-most axis to the inner-most.</p></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L179">view source</a></div></div><div class="public anchor" id="var-trax"><h3>trax</h3><div class="usage"><code>(trax f a x &amp; xs)</code></div><div class="doc"><div class="markdown"><p>trace, or tensor contraction.</p>
<pre><code>f : (Tsor q s)  ^{m} -&gt; t
a : (Vect q (Vect m int))
x : (Tsor r s)
 -&gt; (Tsor ((r - q) * m) t)
</code></pre>
<p><em>a</em> for axis is a rank-<code>[0,2]</code> tensor broadcastable to <code>[q m]</code> where <em>q</em> is the number of axes being contracted simultanously and <em>m</em> the number of input tensors. each row in <em>a</em> specifies the axes of contraction for all input tensors.</p>
<p>when <em>a</em> is a vector of integers, by broadcasting logic, only one axis is contracted from each tensor. the same applies when it’s just an integer, which however may point to different axes for different tensors, should it be a negative index.</p>
<p>the following <em>f</em> can be used for the usual numeric tensor dot.</p>
<pre><code class="clojure">(comp (partial reduce +) (partial rank 1) (partial plux -1 *))
</code></pre></div></div><div class="src-link"><a href="https://github.com/ysmiraak/home/blob/master/src/ysmiraak/tensor.clj#L286">view source</a></div></div></div></body></html>